\section{Reinforcement Learning Model}
\subsection{Overview}
RL is 

We used Soft Actor-Critic (SAC) \cite{haarnoja2018soft} provided in RLkit, an open-source RL framework implemented in PyTorch\cite{pongrlkit}, as our RL model.
\par
\subsection{SAC}
Soft Actor-Critic (SAC) is an DRL algorithm that optimizes a stochastic policy in an off-policy way.
Unlike other RL models, which usually optimize the expected return, SAC optimizes the policy with entropy regularization and takes entropy, measuring randomness in the policy, into account.
\par
\subsection{Reward Scale}
SAC is highly sensitive to the scaling of the reward. If the reward scale is too small, the reward will fail to affect the model, and the policy will become nearly uniform. The model will learn quickly and become deterministic for reward scale too large, leaving no room for exploration.